<!DOCTYPE html>
<html>

<!--Technical Stuff, Imports-->
<script src="js/scripts.js"></script>

<head>
	
	<title>2004-902</title>
	<link href="css/main.css" rel="stylesheet" type="text/css" />
	<link href="https://fonts.googleapis.com/css?family=Kanit:400,600,800" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Carter+One" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

</head>

<!--Page Content-->
<body>

	<div class="wrapper">

		<div class="sidebar" style="display:none; width: 0%;" id="sidebar"></div>

		<div class="titlebar" style="width: 70%; margin-left: 10%;" id="titlebar">


			<img class="sidebarButton" src="img/openSidebar.png" width="30" height="30" onclick="sidebarToggle();"/>
			<p class="titleText1">
				Awards
			</p>
			<p class="titleText2">
				
			</p>

		</div>

		<div class="main" style="width: 70%; margin-left: 10%;" id="main">
			<center>
				<img src="img/safety-concerms.jpg" width="60%" >
			</center>

			<p class="subtitleText2">
				Saftey Concerns
			</p>

			<p class="bodyText1">
				Safety of Artificial Intelligence revolves around one question, “How can we ensure safety for a technology that is designed to learn how to modify its own behavior?” explains Journalist Ariel Conn from Future of Life Institute. This question has come into higher debate with the advancements of machine and deep learning which improves and adapts on its own from prior experiences in addition to analyzing data. Therefore safety guards must be developed for unforeseen situations. For each major technological breakthrough safety must be addresses with updated regulations to follow in order for everyone to remain safe.
				<br></br>
				Many citizens are weary to the new technology of AI and the possibility of driverless cars or high intelligent drones. This is a natural response as trust must be established with the new AI systems, similar to our trust in an airplane flying across the sky, or an ATM to register a deposit. Trust can only become established in intricate safety precautions that ensure the highest implementation of safe and ethical practices, legislation, social morals, and ensures the protection of personal or private informations. Trust of AI has certainly been questioned with the media emphasising AI failures to the public creating a common misconception of lack in safety features. AI malfunctions occur from learning negative behavior or misunderstandings from its surrounding environment. A prime example of AI malfunctions from negative behavior is Microsoft’s chatbot Tay. With the Microsoft’s good intentions to “engage and entertain people where they connect with each other online through casual and playful conversation” users began to hijak the chatbot, repeating racist statements, learning from those interactions, and repeating them. As a result of negative interactions with users Tay learned politically incorrect statements causing a horrific turn of events. One example of AI technology misunderstanding the environment is the Tesla car accident. This occurs when a car was on Autopilot mode and failed to differentiate between the clear sky and an oncoming white truck resulting in a fatal collision. Many scientists are concerned about the slow improvements in AI with the constant obstacle of safety. Ian Goodfellow, a scientist for google brain, suggests easy solution for this lack of safety through traditional security methods. “Applying traditional security techniques to AI gives us a concrete path to achieving AI safety. If we can design a method that prevents even malicious attackers from causing an AI to take an undesirable action, then it is even less likely that the AI would choose an undesirable action independently.” emphasises Goodfellow.
				<br></br>
				Safety not only must require built trust with consumers but also value alignment. Value alignment can be difficult for computer technologies as humans have a large range of values, some of which are viewed as bad. With the near future of Artificial Intelligence meeting and surpassing human intelligence value alignment is becoming a larger safety concern because the machines are harder to control. University of Connecticut philosophy Susan Schneider expresses this concerns when explaining, “We can’t even make sure fellow humans have the right goals; why should we think AI will have values that align with ours, let alone that a superintelligence would.”
				<br></br>
				With companies prioritizing the development of the newest fastest technology safety is put in the back seat and forgotten. This is unacceptable when the price of these technologies come with the harming of others. If AI desires to have a successful future, safety and technology must work together hand-and-hand.
			</p>

			<br></br>

		</div>

	</div>

</body>

</html>

	
